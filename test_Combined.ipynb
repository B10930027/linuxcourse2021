{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM98tEvcF0PJsewTc0sB6rQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/B10930027/linuxcourse2021/blob/main/test_Combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools\n",
        "!pip install twine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmBAgFfvi8cG",
        "outputId": "d63de294-718e-4910-d2b0-47b85b8210fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting twine\n",
            "  Downloading twine-4.0.2-py3-none-any.whl (36 kB)\n",
            "Collecting pkginfo>=1.8.1 (from twine)\n",
            "  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\n",
            "Collecting readme-renderer>=35.0 (from twine)\n",
            "  Downloading readme_renderer-42.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from twine) (2.31.0)\n",
            "Collecting requests-toolbelt!=0.9.0,>=0.8.0 (from twine)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from twine) (2.0.7)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.10/dist-packages (from twine) (6.8.0)\n",
            "Requirement already satisfied: keyring>=15.1 in /usr/lib/python3/dist-packages (from twine) (23.5.0)\n",
            "Collecting rfc3986>=1.4.0 (from twine)\n",
            "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from twine) (13.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=3.6->twine) (3.17.0)\n",
            "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine)\n",
            "  Downloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine) (0.18.1)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->twine) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->twine) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->twine) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->twine) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine) (0.1.2)\n",
            "Installing collected packages: nh3, rfc3986, readme-renderer, pkginfo, requests-toolbelt, twine\n",
            "Successfully installed nh3-0.2.14 pkginfo-1.9.6 readme-renderer-42.0 requests-toolbelt-1.0.0 rfc3986-2.0.0 twine-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir tiger_Age"
      ],
      "metadata": {
        "id": "biz2frZ-kJUu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tiger_Age/setup.py\n",
        "\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "setup(\n",
        "    name='tiger_Age',\n",
        "    version='0.1',\n",
        "    author='Kaina',\n",
        "    author_email='b10930027@gapps.ntust.edu.tw',\n",
        "    packages=find_packages(),\n",
        "    install_requires=[\n",
        "        'numpy',\n",
        "        'scipy',\n",
        "        'opencv-python',\n",
        "        'nibabel',\n",
        "        'pandas',\n",
        "        'scikit-learn',\n",
        "        'tensorflow',\n",
        "        'keras',\n",
        "    ],  # 依赖项列表\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fqyC83BjPW9",
        "outputId": "9e4ea01d-17f2-4c6d-eca3-f184d7ccbdc2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tiger_Age/setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xTIpDbz75KJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c048c1-057e-4394-e2e4-5b9cc640abee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tiger_Age/TrainingData_Volume.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tiger_Age/TrainingData_Volume.py\n",
        "\n",
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "import os\n",
        "import re\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import openpyxl as opl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from nibabel import filename_parser\n",
        "from pandas.core.indexers.utils import length_of_indexer\n",
        "\n",
        "# Add your 'Age' array here\n",
        "# age = [age1, age2, ...]\n",
        "\n",
        "mask_dir = input(\"Path TrainingData(IXI)：\")\n",
        "# mask_dir = \"/content/IXI_T1\"\n",
        "mask_file = list(Path(mask_dir).glob('*.nii.gz'))\n",
        "file_count = len(mask_file)\n",
        "\n",
        "label = [2, 3, 4, 5, 7, 8, 10, 11, 12, 13,\n",
        "         14, 15, 16, 17, 18, 26, 28, 30, 31, 41, 42,\n",
        "         43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 58,\n",
        "         60, 62, 63, 77, 85, 251, 252, 253, 254, 255]\n",
        "\n",
        "# Read Age data from Excel\n",
        "age_data = input(\"Path AgeData(IXI)：\")\n",
        "age_df = pd.read_excel(age_data)\n",
        "\n",
        "volume = np.zeros((file_count, len(label)), dtype=np.longdouble)\n",
        "\n",
        "volume_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each label\n",
        "for idx, element in enumerate(label):\n",
        "    i = 0\n",
        "    for i, file in enumerate(mask_file):\n",
        "        file_name = os.path.basename(file)\n",
        "        parts = file_name.split(\"_\")\n",
        "        number = parts[0][2:]  # Get the numeric part after CC\n",
        "        img = nib.load(file)\n",
        "        data = img.get_fdata()\n",
        "        [sx, sy, sz] = img.header.get_zooms()\n",
        "        pixel_volume = sx * sy * sz  # 1 mm^3\n",
        "        pixel_amount = np.sum(data == element)\n",
        "        total_volume = pixel_amount * pixel_volume\n",
        "        volume[i, idx] = total_volume\n",
        "    # Append the data for this label to volume_df\n",
        "    volume_df[element] = volume[:, idx]\n",
        "\n",
        "# Combine Age and volume data into a single DataFrame\n",
        "result_df = pd.concat([age_df, volume_df], axis=1)\n",
        "\n",
        "# Save the result to a new Excel file\n",
        "result_df.to_excel(\"IXI_Dataset.xlsx\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tiger_Age/AgePredictig.py\n",
        "\n",
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "import os\n",
        "import re\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import openpyxl as opl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from nibabel import filename_parser\n",
        "from pandas.core.indexers.utils import length_of_indexer\n",
        "\n",
        "# Add your 'Age' array here\n",
        "# age = [age1, age2, ...]\n",
        "\n",
        "# address of masks\n",
        "mask_dir = input(\"Path TestingData(cc359)：\")\n",
        "# mask_dir = \"/content/cc359\"\n",
        "mask_file = list(Path(mask_dir).glob('*.nii.gz'))\n",
        "file_count = len(mask_file)\n",
        "\n",
        "# freeSurfer Brain Labeling\n",
        "label = [  2,  3,   4,  5,   7,  8,  10,  11,  12,\n",
        "       13,  14,  15,  16,  17,  18,  26,  28,  41,\n",
        "       42,  43,  44,  46,  47,  49,  50,  51,  52,\n",
        "       53,  54,  58,  60 ]\n",
        "\n",
        "# Read Age data from Excel\n",
        "age_data = input(\"Path AgeData(cc359)：\")\n",
        "age_df = pd.read_excel(age_data)\n",
        "\n",
        "volume = np.zeros((file_count, len(label)), dtype=np.longdouble)\n",
        "\n",
        "volume_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each label\n",
        "for idx, element in enumerate(label):\n",
        "    i = 0\n",
        "    for i, file in enumerate(mask_file):\n",
        "        file_name = os.path.basename(file)\n",
        "        parts = file_name.split(\"_\")\n",
        "        number = parts[0][2:]  # Get the numeric part after CC\n",
        "        img = nib.load(file)\n",
        "        data = img.get_fdata()\n",
        "        [sx, sy, sz] = img.header.get_zooms()\n",
        "        pixel_volume = sx * sy * sz  # 1 mm^3\n",
        "        pixel_amount = np.sum(data == element)\n",
        "        total_volume = pixel_amount * pixel_volume\n",
        "        volume[i, idx] = total_volume\n",
        "    # Append the data for this label to volume_df\n",
        "    volume_df[element] = volume[:, idx]\n",
        "\n",
        "# Combine Age and volume data into a single DataFrame\n",
        "result_df = pd.concat([age_df, volume_df], axis=1)\n",
        "\n",
        "# Save the result to a new Excel file\n",
        "result_df.to_excel(\"cc359_Dataset.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "gjUd_GxtVukY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3aa1d50-7723-4872-e256-cd77d0e2ab6e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tiger_Age/AgePredictig.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "q-dofjv9lLDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf3b688-bfc1-4e7e-a9d3-758c46622376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tiger_Age/TestingData_Volume.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tiger_Age/TestingData_Volume.py\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.optimizers import Adam\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# 0. 載入資料集（假設已經完成資料預處理和切分）\n",
        "\n",
        "# 讀取Training資料集\n",
        "df1 = pd.read_excel(\"IXI_Dataset.xlsx\")\n",
        "# 讀取Testing資料集\n",
        "df2 = pd.read_excel(\"cc359_Dataset.xlsx\")\n",
        "\n",
        "# 將腦組織體積大小作為特徵\n",
        "\n",
        "# freeSurfer Brain Labeling\n",
        "label = [  2,  3,   4,  5,   7,  8,  10,  11,  12,\n",
        "        13,  14,  15,  16,  17,  18,  26,  28,  41,\n",
        "        42,  43,  44,  46,  47,  49,  50,  51,  52,\n",
        "        53,  54,  58,  60   ]\n",
        "\n",
        "X1 = df1[[   2,  3,   4,  5,   7,  8,  10,  11,  12,\n",
        "        13,  14,  15,  16,  17,  18,  26,  28,  41,\n",
        "        42,  43,  44,  46,  47,  49,  50,  51,  52,\n",
        "        53,  54,  58,  60 ]].values\n",
        "\n",
        "X2 = df2[[   2,  3,   4,  5,   7,  8,  10,  11,  12,\n",
        "        13,  14,  15,  16,  17,  18,  26,  28,  41,\n",
        "        42,  43,  44,  46,  47,  49,  50,  51,  52,\n",
        "        53,  54,  58,  60 ]].values\n",
        "\n",
        "\n",
        "# 將實際年齡作為目標\n",
        "y1 = df1['Age'].values\n",
        "y2 = df2['Age'].values\n",
        "\n",
        "# 資料合併\n",
        "x_y1 = []\n",
        "x_y2 = []\n",
        "for i in range(len(X1)):\n",
        "  x_y1.append([X1[i],y1[i]])\n",
        "for i in range(len(X2)):\n",
        "  x_y2.append([X2[i],y2[i]])\n",
        "\n",
        "# 分割資料集\n",
        "xy_train = x_y1 # Traing_Data = IXI\n",
        "xy_test = x_y2 # Test_Data = cc359\n",
        "\n",
        "# 設定訓練集和測試集的特徵和標籤\n",
        "# Traing_Data = IXI\n",
        "x_train = [x for x, _ in xy_train]\n",
        "y_train = [y for _, y in xy_train]\n",
        "\n",
        "# Test_Data = cc359\n",
        "x_test = [x for x, _ in xy_test]\n",
        "y_test = [y for _, y in xy_test]\n",
        "\n",
        "# 1: 數據正規化\n",
        "scaler = StandardScaler()\n",
        "x_train_normalized = scaler.fit_transform(x_train)\n",
        "x_test_normalized = scaler.transform(x_test)\n",
        "\n",
        "# 2: 特徵選擇\n",
        "\n",
        "# 計算每個腦組織的方差\n",
        "variances = np.var(x_train_normalized, axis=0)\n",
        "\n",
        "# 計算每個腦組織於年齡的相關性\n",
        "correlations = [np.corrcoef(x_train_normalized[:, i], y_train)[0, 1] for i in range(x_train_normalized.shape[1])]\n",
        "\n",
        "# 設置選擇的閾值\n",
        "variance_threshold = 0.25  # 方差閾值\n",
        "correlation_threshold = 0.04  # 相關性閾值\n",
        "\n",
        "# 選擇具有高方差且年齡的相關性大的腦組織\n",
        "selected_features = [i for i in range(x_train_normalized.shape[1]) if variances[i] > variance_threshold and abs(correlations[i]) > correlation_threshold]\n",
        "selected_index = [label[i] for i in selected_features]\n",
        "print(\"Selected features:\", selected_index) # 印出特徵索引\n",
        "\n",
        "# 根据選擇的特徵索引提取特徵\n",
        "x_train_selected = x_train_normalized[:, selected_features]\n",
        "x_test_selected = x_test_normalized[:, selected_features]\n",
        "\n",
        "\n",
        "# 3: 建立MLP模型\n",
        "def create_model(input_dim=x_train_selected[0].shape[0], hidden_units=64, batch_size=32, epochs=50):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_units, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(hidden_units, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004)\n",
        "    model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "class NotFittedError(RuntimeError):\n",
        "    def __init__(self, message=\"This CustomKerasRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using 'predict'.\"):\n",
        "        self.message = message\n",
        "        super().__init__(self.message)\n",
        "\n",
        "class CustomKerasRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, input_dim=x_train_selected[0].shape[0], hidden_units=64, batch_size=32, epochs=50):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_units = hidden_units\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = create_model(\n",
        "            input_dim=self.input_dim,\n",
        "            hidden_units=self.hidden_units,\n",
        "            batch_size=self.batch_size,\n",
        "            epochs=self.epochs\n",
        "        )\n",
        "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
        "        self.is_fitted_ = True\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        try:\n",
        "            return self.model.predict(X)\n",
        "        except AttributeError:\n",
        "            raise NotFittedError(\"This CustomKerasRegressor instance is not fitted yet. \")\n",
        "\n",
        "# 創建 KerasRegressorWrapper 估計器\n",
        "custom_keras_regressor = CustomKerasRegressor()\n",
        "\n",
        "# 定義要搜索的超參數網格\n",
        "MLP_params = {\n",
        "    'hidden_units': [64],  # 可以調整不同的hidden_units值\n",
        "    'batch_size': [32],  # 訓練的批次大小\n",
        "    'epochs': [255]  # 訓練的時代數\n",
        "}\n",
        "\n",
        "# 5. 使用交叉驗證評估模型\n",
        "# 定義交叉驗證，以選擇最佳的參數 (fold=5, shuffle要洗牌, random_state要定義一個固定的數確定結果)\n",
        "cv = KFold(n_splits=10)\n",
        "\n",
        "# 進行網格搜索來找到最佳參數\n",
        "grid_search = GridSearchCV(estimator=custom_keras_regressor, param_grid=MLP_params, cv=cv, scoring='neg_mean_absolute_error')\n",
        "grid_search.fit(np.array(x_train_selected), np.array(y_train))\n",
        "\n",
        "# 輸出最佳參數\n",
        "# 使用 best_estimator_ 屬性獲取具有最佳參數的模型\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "best_model = grid_search.best_estimator_\n",
        "# 輸出每個折疊（fold）中的評估分數\n",
        "cv_scores = cross_val_score(best_model, np.array(x_train_selected), np.array(y_train), cv=cv, scoring='neg_mean_absolute_error')\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", np.mean(cv_scores))\n",
        "\n",
        "# 6. 模型訓練\n",
        "# best_model.fit(np.array(x_train_selected), np.array(y_train))\n",
        "y_train_pred = best_model.predict(np.array(x_train_selected))\n",
        "error = abs(y_train_pred-np.array(y_train))\n",
        "# for index, value in enumerate(y_train_pred):\n",
        "#     print(f\"資料編號 {index}：{value}\")\n",
        "# for index, value in enumerate(np.array(y_train)):\n",
        "#     print(f\"資料編號 {index}：{value}\")\n",
        "print(np.round(error), sep='\\n')\n",
        "mae_train = mean_absolute_error(np.array(y_train), y_train_pred)\n",
        "print(\"Training MAE:\", mae_train)\n",
        "\n",
        "\n",
        "# 7. 模型評估\n",
        "y_test_pred = best_model.predict(np.array(x_test_selected))\n",
        "error = abs(y_test_pred-np.array(y_test))\n",
        "# print(np.round(error), sep='\\n')\n",
        "mae = mean_absolute_error(np.array(y_test), y_test_pred)\n",
        "print('Testing Loss:', mae)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd tiger_Age && python setup.py sdist bdist_wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqncqo-vqzmc",
        "outputId": "cb321c7e-8433-49b7-c5d7-51a21ef5d7a3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running sdist\n",
            "running egg_info\n",
            "creating tiger_Age.egg-info\n",
            "writing tiger_Age.egg-info/PKG-INFO\n",
            "writing dependency_links to tiger_Age.egg-info/dependency_links.txt\n",
            "writing requirements to tiger_Age.egg-info/requires.txt\n",
            "writing top-level names to tiger_Age.egg-info/top_level.txt\n",
            "writing manifest file 'tiger_Age.egg-info/SOURCES.txt'\n",
            "reading manifest file 'tiger_Age.egg-info/SOURCES.txt'\n",
            "writing manifest file 'tiger_Age.egg-info/SOURCES.txt'\n",
            "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
            "\n",
            "running check\n",
            "creating tiger_Age-0.1\n",
            "creating tiger_Age-0.1/tiger_Age.egg-info\n",
            "copying files to tiger_Age-0.1...\n",
            "copying setup.py -> tiger_Age-0.1\n",
            "copying tiger_Age.egg-info/PKG-INFO -> tiger_Age-0.1/tiger_Age.egg-info\n",
            "copying tiger_Age.egg-info/SOURCES.txt -> tiger_Age-0.1/tiger_Age.egg-info\n",
            "copying tiger_Age.egg-info/dependency_links.txt -> tiger_Age-0.1/tiger_Age.egg-info\n",
            "copying tiger_Age.egg-info/requires.txt -> tiger_Age-0.1/tiger_Age.egg-info\n",
            "copying tiger_Age.egg-info/top_level.txt -> tiger_Age-0.1/tiger_Age.egg-info\n",
            "Writing tiger_Age-0.1/setup.cfg\n",
            "creating dist\n",
            "Creating tar archive\n",
            "removing 'tiger_Age-0.1' (and everything under it)\n",
            "running bdist_wheel\n",
            "running build\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_egg_info\n",
            "Copying tiger_Age.egg-info to build/bdist.linux-x86_64/wheel/tiger_Age-0.1-py3.10.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/tiger_Age-0.1.dist-info/WHEEL\n",
            "creating 'dist/tiger_Age-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'tiger_Age-0.1.dist-info/METADATA'\n",
            "adding 'tiger_Age-0.1.dist-info/WHEEL'\n",
            "adding 'tiger_Age-0.1.dist-info/top_level.txt'\n",
            "adding 'tiger_Age-0.1.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keyring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yQ5RI5msHVk",
        "outputId": "f4a0ecb3-5bcd-4982-da95-c59147643cf4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keyring in /usr/lib/python3/dist-packages (23.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!twine upload --verbose --username __token__ --password \"pypi-AgEIcHlwaS5vcmcCJDg4MzNlY2ZjLTIxYTItNDRiYi1iMDMzLWNiZDQyZGY1MjdjNQACKlszLCJkMmY0ODcxOS1mMGZmLTQyNDUtYTUzZC1iYzdmMzViODg2NzMiXQAABiDKFiTXtKN4eAgLz498i4MxlYQ_RRL-DoUDcbNgbIjcnA\" tiger_Age/dist/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzgvUPz2q3hM",
        "outputId": "25dda940-610f-4316-eb52-40333312de31"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading distributions to https://upload.pypi.org/legacy/\n",
            "\u001b[34mINFO    \u001b[0m tiger_Age/dist/tiger_Age-0.1-py3-none-any.whl (1.0 KB)                                     \n",
            "\u001b[34mINFO    \u001b[0m tiger_Age/dist/tiger_Age-0.1.tar.gz (0.9 KB)                                               \n",
            "\u001b[34mINFO    \u001b[0m username set by command options                                                            \n",
            "\u001b[34mINFO    \u001b[0m password set by command options                                                            \n",
            "\u001b[34mINFO    \u001b[0m username: __token__                                                                        \n",
            "\u001b[34mINFO    \u001b[0m password: <hidden>                                                                         \n",
            "Uploading tiger_Age-0.1-py3-none-any.whl\n",
            "\u001b[2K\u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 kB\u001b[0m • \u001b[33m00:00\u001b[0m • \u001b[31m?\u001b[0m\n",
            "\u001b[?25h\u001b[34mINFO    \u001b[0m Response from https://upload.pypi.org/legacy/:                                             \n",
            "         200 OK                                                                                     \n",
            "Uploading tiger_Age-0.1.tar.gz\n",
            "\u001b[2K\u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 kB\u001b[0m • \u001b[33m00:00\u001b[0m • \u001b[31m?\u001b[0m\n",
            "\u001b[?25h\u001b[34mINFO    \u001b[0m Response from https://upload.pypi.org/legacy/:                                             \n",
            "         200 OK                                                                                     \n",
            "\n",
            "\u001b[32mView at:\u001b[0m\n",
            "https://pypi.org/project/tiger-Age/0.1/\n"
          ]
        }
      ]
    }
  ]
}